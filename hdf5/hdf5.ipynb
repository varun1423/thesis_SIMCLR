{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f744fe6f2719b3888fef47857be378108051e5590210f380c70d40a1bbe27ebd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tarfile\n",
    "from PIL import  Image\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hdf5(csv_in, root_dir, data_dir ,out_hdf5_file_name):\n",
    "    dataframe_train = pd.read_csv(csv_in)\n",
    "    for tv in [data_dir]:\n",
    "        target_dir = os.path.join(root_dir, tv) \n",
    "\n",
    "        target_files = list(dataframe_train['Image_Name'])\n",
    "        encoding = list(dataframe_train['encoding'])\n",
    "\n",
    "        perm = np.random.permutation(len(dataframe_train['encoding']))\n",
    "        encoding = np.array(encoding)\n",
    "        encoding = encoding[perm]\n",
    "\n",
    "        target_files = np.array(target_files)\n",
    "        target_files = target_files[perm]\n",
    "\n",
    "        img_file = list()\n",
    "        for file in target_files:\n",
    "            img_file.append(os.path.join(target_dir,file))\n",
    "        data_files_list = list()\n",
    "        for file in img_file:\n",
    "            temp = Image.open(file)\n",
    "            keep=temp.copy()\n",
    "            data_files_list.append(keep)\n",
    "            temp.close()\n",
    "    print(\"creating file\")\n",
    "    fi = h5py.File(out_hdf5_file_name, 'w')\n",
    "    print(\"creating dset\")\n",
    "    dset = fi.create_dataset('data', shape=(len(encoding), 256, 256))\n",
    "    print(\"creating lset\")\n",
    "    lset = fi.create_dataset('labels', shape=(len(encoding),1), dtype=int)\n",
    "    startt = time.time()\n",
    "    for idx, (f, l) in enumerate(zip(data_files_list, encoding)):\n",
    "        dset[idx] = f\n",
    "        lset[idx] = l\n",
    "        now = time.time()\n",
    "        time_remaining = len(data_files_list) * (now - startt) / (idx + 1)\n",
    "        if idx % 10 == 0:\n",
    "            print(idx, time_remaining / 60, f, l)\n",
    "    fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_in = \"D:\\TUD\\TU_Dresden\\WiSe_2021\\Thesis_FZJ/tbc_with_lifetime/pretraining_trainset.csv\"\n",
    "root_dir = \"D:/TUD/TU_Dresden/WiSe_2021/Thesis_FZJ/tbc_with_lifetime/\"\n",
    "data_dir = \"data_with_Lifetime\"\n",
    "out_hdf5_file_name = \"tbc_train_data_hdf5.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "write_hdf5(csv_in, root_dir, data_dir, out_hdf5_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_in = \"D:\\TUD\\TU_Dresden\\WiSe_2021\\Thesis_FZJ/tbc_with_lifetime/fine_tune_validation.csv\"\n",
    "out_hdf5_file_name = \"tbc_validation_data_hdf5.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "write_hdf5(csv_in, root_dir, data_dir, out_hdf5_file_name)"
   ]
  }
 ]
}